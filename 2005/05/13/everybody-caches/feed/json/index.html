{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://blog.josephscott.org/2005/05/13/everybody-caches/feed/json/ -- and add it your reader.",
    "home_page_url": "https://blog.josephscott.org/2005/05/13/everybody-caches/",
    "feed_url": "https://blog.josephscott.org/2005/05/13/everybody-caches/feed/json/",
    "language": "en-US",
    "title": "Comments on: Everybody Caches",
    "items": [
        {
            "id": "https://blog.josephscott.org/2005/05/13/everybody-caches/#comment-805",
            "url": "https://blog.josephscott.org/2005/05/13/everybody-caches/#comment-805",
            "content_html": "As a SuSE newbe, we ran into the following problem dealing with data acquisition card under development, based on the PLX housekeeping chip. The problem appears to be associated with the OS and not our code, as we release memory at close. To wit:\n:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\nMy  CS major Co-op students have developed a C++ program that works just fine. We use either one or two DMA buffers (two different programs - one uses hyperthreading) that set aside just enough memory for a DMA transfer for a single pulse echo,  512  2-byte words. When I watch the hard disk light operate during acquisition, it blinks about every five seconds, suggesting caching going on. We collect data for say 15 minutes in the extreme case, creating data files of 800 MB or so. The computer has 1 GB of memory. The first aqusition goes just fine. Checking the cache buildup during the acqusition, at it appears that the OS sets up a new block of cache for each DMA transfer, which I guess makes sense from its perspective, but then uses 800 MB of memory in the process. When the program runs a second time and builds another 800 MB file, I get gaps in the output data, as eveidence by the image we create, losing azimuth sectors of data, , suggesting trigger drops. My take on this is that it occurs when the OS runs out of fresh memory for caching, then has to go back and release previous cache, ignoring trigers while it releases cache and thus missing new data transfers.\n\nOur solution has been to simply reboot the system after each acqusition.The collection occurs on the hr/hf-hr using  CRON. You don't even have to log on, and the collection runs regularly, then reboots. Clearly this is a clumsy workaround. Any sugestions?",
            "content_text": "As a SuSE newbe, we ran into the following problem dealing with data acquisition card under development, based on the PLX housekeeping chip. The problem appears to be associated with the OS and not our code, as we release memory at close. To wit:\n:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\nMy  CS major Co-op students have developed a C++ program that works just fine. We use either one or two DMA buffers (two different programs - one uses hyperthreading) that set aside just enough memory for a DMA transfer for a single pulse echo,  512  2-byte words. When I watch the hard disk light operate during acquisition, it blinks about every five seconds, suggesting caching going on. We collect data for say 15 minutes in the extreme case, creating data files of 800 MB or so. The computer has 1 GB of memory. The first aqusition goes just fine. Checking the cache buildup during the acqusition, at it appears that the OS sets up a new block of cache for each DMA transfer, which I guess makes sense from its perspective, but then uses 800 MB of memory in the process. When the program runs a second time and builds another 800 MB file, I get gaps in the output data, as eveidence by the image we create, losing azimuth sectors of data, , suggesting trigger drops. My take on this is that it occurs when the OS runs out of fresh memory for caching, then has to go back and release previous cache, ignoring trigers while it releases cache and thus missing new data transfers.\n\nOur solution has been to simply reboot the system after each acqusition.The collection occurs on the hr/hf-hr using  CRON. You don't even have to log on, and the collection runs regularly, then reboots. Clearly this is a clumsy workaround. Any sugestions?",
            "date_published": "2005-06-07T13:05:53-06:00",
            "authors": [
                {
                    "name": "Dennis Trizna",
                    "url": "",
                    "avatar": "https://secure.gravatar.com/avatar/80e88825daec38a4742eeebd8df882c1?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "Dennis Trizna",
                "url": "",
                "avatar": "https://secure.gravatar.com/avatar/80e88825daec38a4742eeebd8df882c1?s=512&d=mm&r=g"
            }
        }
    ]
}