<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Web &#8211; Joseph Scott</title>
	<atom:link href="/tag/web/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description></description>
	<lastBuildDate>Thu, 28 Jan 2016 15:25:26 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<atom:link rel='hub' href='/?pushpress=hub'/>
	<item>
		<title>Longevity On The Web</title>
		<link>/2016/01/28/longevity-on-the-web/</link>
					<comments>/2016/01/28/longevity-on-the-web/#respond</comments>
		
		<dc:creator><![CDATA[josephscott]]></dc:creator>
		<pubDate>Thu, 28 Jan 2016 15:25:26 +0000</pubDate>
				<category><![CDATA[Posts]]></category>
		<category><![CDATA[michael-arestad]]></category>
		<category><![CDATA[Web]]></category>
		<guid isPermaLink="false">https://josephscott.org/?p=14907</guid>

					<description><![CDATA[Michael Arestad laments the temporary web: Everything I create on the web feels temporary and fragile. &#8230; Once again, I ask, is there a place for permanency on the web? The comparison to books comes up. I suspect printing multiple copies, that individually are easy to transport long distances, is what gives some books reasonable [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Michael Arestad laments <a href="http://blog.michaelarestad.com/2016/01/11/the-temporary-web/">the temporary web</a>:</p>
<blockquote><p>
Everything I create on the web feels temporary and fragile.<br />
&#8230;<br />
Once again, I ask, is there a place for permanency on the web?
</p></blockquote>
<p>The comparison to books comes up.  I suspect printing multiple copies, that individually are easy to transport long distances, is what gives some books reasonable odds at being around for a long time.  It isn&#8217;t easy to be sure that you&#8217;ve destroyed every single copy of a book.</p>
<p>On the web many sites are hosted on a single server ( or service ), making them relatively easy to wipe out with one shot.</p>
<p>Perhaps the closest thing we have on the Internet today to the mass copy and disperse approach is BitTorrent.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2016/01/28/longevity-on-the-web/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>rwasa</title>
		<link>/2015/10/16/rwasa/</link>
					<comments>/2015/10/16/rwasa/#respond</comments>
		
		<dc:creator><![CDATA[josephscott]]></dc:creator>
		<pubDate>Fri, 16 Oct 2015 12:30:20 +0000</pubDate>
				<category><![CDATA[Posts]]></category>
		<category><![CDATA[rwasa]]></category>
		<category><![CDATA[Web]]></category>
		<guid isPermaLink="false">https://josephscott.org/?p=13320</guid>

					<description><![CDATA[If you are keeping a collection of web servers, I&#8217;ve got a new one for you &#8211; rwasa ( emphasis mine ): rwasa is our full-featured, high performance, scalable web server designed to compete with the likes of nginx. It has been built from the ground-up with no externel library dependencies entirely in x86_64 assembly [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>If you are keeping a collection of web servers, I&#8217;ve got a new one for you &#8211; <a href="https://2ton.com.au/rwasa/">rwasa</a> ( emphasis mine ):</p>
<blockquote><p>
rwasa is our full-featured, high performance, scalable web server designed to compete with the likes of nginx. It has been built from the ground-up with no externel library dependencies <strong>entirely in x86_64 assembly</strong> language, and is the result of many years&#8217; experience with high volume web environments. In addition to all of the common things you&#8217;d expect a modern web server to do, we also include assembly language function hooks ready-made to facilitate Rapid Web Application Server (in Assembler) development.
</p></blockquote>
<p>Yep, written in x86_64 assembly.  Their <a href="https://2ton.com.au/rwasa/#perftests">performance tests</a> show it competing nicely against Nginx.  I didn&#8217;t see any mention of HTTP/2 support though.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2015/10/16/rwasa/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>The Loosely Coupled Web</title>
		<link>/2010/06/21/the-loosely-coupled-web/</link>
					<comments>/2010/06/21/the-loosely-coupled-web/#respond</comments>
		
		<dc:creator><![CDATA[josephscott]]></dc:creator>
		<pubDate>Tue, 22 Jun 2010 04:54:36 +0000</pubDate>
				<category><![CDATA[Posts]]></category>
		<category><![CDATA[http]]></category>
		<category><![CDATA[loosely-coupled]]></category>
		<category><![CDATA[Web]]></category>
		<guid isPermaLink="false">http://josephscott.org/?p=2428</guid>

					<description><![CDATA[There are so many terms floating around for the &#8220;the web&#8221;. One that has been overly abused is &#8220;web 2.0&#8221;. Someone mentioned &#8220;web 2.0&#8221; during a conversation the other day and it reminded me that I had never written about my favorite alternative &#8220;web&#8221; term: &#8220;the loosely coupled web&#8221;. I&#8217;ve been tempted by &#8220;the open [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>There are so many terms floating around for the &#8220;the web&#8221;.  One that has been overly abused is &#8220;web 2.0&#8221;.  Someone mentioned &#8220;web 2.0&#8221; during a conversation the other day and it reminded me that I had never written about my favorite alternative &#8220;web&#8221; term: &#8220;the loosely coupled web&#8221;.  I&#8217;ve been tempted by &#8220;the open web&#8221;, but the term open has been smashed beyond recognition.</p>
<p>What do I mean by loosely coupled?  It means I can start a new site that provides specific services, and people can easily build off it without my intervention.   A great general example of this is the core of the web itself: HTTP.  When you put up a new site browsers just work with it, right out of the box.</p>
<p>Another example is WordPress and the XML-RPC APIs.  If you want to write a new blog client that works with WordPress you don&#8217;t need to create an account any where or sign up for anything extra.  You make use of the common APIs that WordPress provides and go to town.  RSS and Atom feeds fall into the same category.</p>
<p>I think it is also possible to be loosely coupled in a more specific scope.  For example some of Facebook&#8217;s <a href="http://developers.facebook.com/docs/api">Graph API</a> I&#8217;d consider loosely coupled.  You need to know a little bit about it to understand how to make requests and how to read the responses, but that&#8217;s it.  And I like the low barrier that loosely coupled implies.  As you get deeper there are additional requirements, but at least to get started there is very little friction.</p>
<p>I&#8217;m no where near the first to use this term ( a quick <a href="http://www.google.com/search?q=the+loosely+coupled+web">Google search</a> turns up plenty of hits ), but I don&#8217;t think it has received as much respect as it deserves.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2010/06/21/the-loosely-coupled-web/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Google Sitemaps</title>
		<link>/2005/06/02/google-sitemaps/</link>
					<comments>/2005/06/02/google-sitemaps/#comments</comments>
		
		<dc:creator><![CDATA[josephscott]]></dc:creator>
		<pubDate>Fri, 03 Jun 2005 05:35:36 +0000</pubDate>
				<category><![CDATA[josephscott]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[ping]]></category>
		<category><![CDATA[search]]></category>
		<category><![CDATA[sitemap]]></category>
		<category><![CDATA[Web]]></category>
		<guid isPermaLink="false">http://joseph.randomnetworks.com/?p=400</guid>

					<description><![CDATA[Last summer I wrote some thoughts about something like a mod_ping for Apache so that search engines could be easily notified when pages on a site change. I was trying to abstract the idea of pings and trackbacks in use by blogs into a general feature that could be used for any site, even one [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Last summer I wrote some thoughts about something like a <a href="http://joseph.randomnetworks.com/archives/2004/08/24/apache-module-idea-mod_ping/">mod_ping for Apache</a> so that search engines could be easily notified when pages on a site change.  I was trying to abstract the idea of pings and trackbacks in use by blogs into a general feature that could be used for any site, even one made out of static files.</p>
<p>The <a href="http://googleblog.blogspot.com/2005/06/webmaster-friendly.html">announcement</a> about <a href="https://www.google.com/webmasters/sitemaps/stats">Google Sitemaps</a> reminded me very much about my mod_ping idea.  It isn&#8217;t the same, but the goal seems to be the same, providing a way for search engines to discover URLs and when they change.  <a href="http://blog.searchenginewatch.com/blog/050602-195224">SearchEngineWatch has an article about it</a> which provides a brief overview of what Google is up to.  More information can be found in the <a href="https://www.google.com/webmasters/sitemaps/docs/en/sitemap-generator.html">help for there sitemap generator tool</a> (and the <a href="http://sourceforge.net/projects/goog-sitemapgen">Source Forge site for the tool</a>), the <a href="https://www.google.com/webmasters/sitemaps/docs/en/faq.html#s9">Google Sitemaps FAQ</a> and the <a href="https://www.google.com/webmasters/sitemaps/docs/en/protocol.html">Sitemap protocol</a> page.</p>
<p>They specifically mention a hope that servers (Apache &amp; IIS) will support this in the future.  In the mean time you can manually <a href="https://www.google.com/webmasters/sitemaps/docs/en/faq.html#s4">ping Google for sitemap updates</a> using something like curl, wget or even your web browser I suppose.  I&#8217;d expect this feature to be built into certain web tools, like blogs and content management systems.  I&#8217;m sure someone will get around to writing a tool for <a href="http://www.wordpress.org/">WordPress</a> to generate a sitemap file, adding to it each time an entry is published and then ping Google to let them know it has been updated.</p>
<p>Will other web search companies adopt this?  Keep an eye on Yahoo!, MSN, AOL, A9 and IceRocket to see if this goes anywhere.  I don&#8217;t think that this will be limited to the &#8220;traditional&#8221; search folks, I&#8217;d think that someone at Technorati, PubSub and maybe Bloglines might come up with some clever uses for this.  If we are really lucky people will learn from history and come up with something like <a href="http://groups.yahoo.com/group/feedmesh/">feedmesh</a> for sitemap pings.</p>
<p>For now I&#8217;ve whipped up a very basic sitemap file at <a href="http://joseph.randomnetworks.com/sitemap.xml">http://joseph.randomnetworks.com/sitemap.xml</a> and pinged Google to let them know about it.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2005/06/02/google-sitemaps/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
	</channel>
</rss>
