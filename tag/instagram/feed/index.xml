<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>instagram &#8211; Joseph Scott</title>
	<atom:link href="/tag/instagram/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description></description>
	<lastBuildDate>Tue, 01 Nov 2011 20:06:17 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<atom:link rel='hub' href='/?pushpress=hub'/>
	<item>
		<title>Redis Hash Efficiency</title>
		<link>/2011/11/01/redis-hash-efficiency/</link>
					<comments>/2011/11/01/redis-hash-efficiency/#respond</comments>
		
		<dc:creator><![CDATA[josephscott]]></dc:creator>
		<pubDate>Tue, 01 Nov 2011 20:06:17 +0000</pubDate>
				<category><![CDATA[Posts]]></category>
		<category><![CDATA[instagram]]></category>
		<category><![CDATA[redis]]></category>
		<guid isPermaLink="false">http://josephscott.org/?p=5024</guid>

					<description><![CDATA[Instagram on switching from plain key => value storage to hashes in Redis: The size difference was pretty striking; with our 1,000,000 key prototype (encoded into 1,000 hashes of 1,000 sub-keys each), Redis only needs 16MB to store the information. Expanding to 300 million keys, the total is just under 5GB—which in fact, even fits [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Instagram on switching from plain key => value storage to hashes in <a href="http://redis.io/">Redis</a>:</p>
<blockquote><p>
The size difference was pretty striking; with our 1,000,000 key prototype (encoded into 1,000 hashes of 1,000 sub-keys each), Redis only needs 16MB to store the information. Expanding to 300 million keys, the total is just under 5GB—which in fact, even fits in the much cheaper m1.large instance type on Amazon, about 1/3 of the cost of the larger instance we would have needed otherwise. Best of all, lookups in hashes are still O(1), making them very quick.
</p></blockquote>
<p>via <a href='http://instagram-engineering.tumblr.com/post/12202313862/storing-hundreds-of-millions-of-simple-key-value-pairs'>Instagram Engineering • Storing hundreds of millions of simple key-value pairs in Redis</a>.</p>
<p>The original key => value storage method used 70MB for 1,000,000 entries.  Making their 300,000,000 target usage in the neighborhood of 21GB.  Going from 21GB to 5GB is a huge win.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2011/11/01/redis-hash-efficiency/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
