{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://blog.josephscott.org/tag/spdy/feed/json/ -- and add it your reader.",
    "home_page_url": "https://blog.josephscott.org/tag/spdy/",
    "feed_url": "https://blog.josephscott.org/tag/spdy/feed/json/",
    "language": "en-US",
    "title": "spdy &#8211; Joseph Scott",
    "items": [
        {
            "id": "https://josephscott.org/?p=11616",
            "url": "https://blog.josephscott.org/2015/02/17/custom-spdy-at-facebook/",
            "title": "Custom SPDY at Facebook",
            "content_html": "<p>With <a href=\"http://blog.chromium.org/2015/02/hello-http2-goodbye-spdy-http-is_9.html\">the Chrome browser already making plans to retire SPDY in favor of HTTP/2</a> I started testing sites to see how many of them <a href=\"https://josephscott.org/archives/2014/12/how-to-check-a-site-for-spdy-support-with-openssl/\">advertised support for HTTP/2</a>.  No surprise that Google does:</p>\n<blockquote><p>\n$ openssl s_client -connect google.com:443 -nextprotoneg &#8221;<br />\nCONNECTED(00000003)<br />\nProtocols advertised by server: <strong>h2-15, h2-14, spdy/3.1, spdy/3, http/1.1</strong>\n</p></blockquote>\n<p>The <code>h2-15</code> and <code>h2-14</code> refer to the HTTP/2 draft version ( <a href=\"https://tools.ietf.org/html/draft-ietf-httpbis-http2-14\">14</a> and <a href=\"https://tools.ietf.org/html/draft-ietf-httpbis-http2-15\">15</a> in this case, draft <a href=\"https://tools.ietf.org/html/draft-ietf-httpbis-http2-17\">17</a> was published last week ).</p>\n<p>The response I got from Facebook turned up something interesting:</p>\n<blockquote><p>\n$ openssl s_client -connect facebook.com:443 -nextprotoneg &#8221;<br />\nCONNECTED(00000003)<br />\nProtocols advertised by server: <strong>spdy/3.1-fb-0.5</strong>, spdy/3.1, spdy/3, http/1.1\n</p></blockquote>\n<p>I don&#8217;t recall seeing <code>spdy/3.1-fb-0.5</code> before.  It comes from the <a href=\"https://github.com/facebook/proxygen/blob/master/proxygen/lib/http/codec/compress/HPACKCodec.cpp#L27\">Facebook proxygen HTTP library</a>.</p>\n<p><a href=\"https://code.google.com/p/chromium/codesearch#chromium/src/net/socket/ssl_client_socket.cc&#038;q=spdy/3.1&#038;sq=package:chromium&#038;l=31&#038;dr=C\">Chrome doesn&#8217;t check for this version of SPDY</a>, I&#8217;m assuming no other regular browsers do either.  My guess is the only clients that support this are Facebook mobile apps.</p>\n",
            "content_text": "With the Chrome browser already making plans to retire SPDY in favor of HTTP/2 I started testing sites to see how many of them advertised support for HTTP/2.  No surprise that Google does:\n\n$ openssl s_client -connect google.com:443 -nextprotoneg &#8221;\nCONNECTED(00000003)\nProtocols advertised by server: h2-15, h2-14, spdy/3.1, spdy/3, http/1.1\n\nThe h2-15 and h2-14 refer to the HTTP/2 draft version ( 14 and 15 in this case, draft 17 was published last week ).\nThe response I got from Facebook turned up something interesting:\n\n$ openssl s_client -connect facebook.com:443 -nextprotoneg &#8221;\nCONNECTED(00000003)\nProtocols advertised by server: spdy/3.1-fb-0.5, spdy/3.1, spdy/3, http/1.1\n\nI don&#8217;t recall seeing spdy/3.1-fb-0.5 before.  It comes from the Facebook proxygen HTTP library.\nChrome doesn&#8217;t check for this version of SPDY, I&#8217;m assuming no other regular browsers do either.  My guess is the only clients that support this are Facebook mobile apps.",
            "date_published": "2015-02-17T18:18:12-07:00",
            "date_modified": "2015-02-17T18:18:12-07:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "facebook",
                "http2",
                "spdy",
                "Posts"
            ]
        },
        {
            "id": "https://josephscott.org/?p=11433",
            "url": "https://blog.josephscott.org/2014/12/03/nginx-1-7-8-fixes-200ms-delay-with-spdy/",
            "title": "Nginx 1.7.8 \u2013 Fixes 200ms Delay With SPDY",
            "content_html": "<p><a href=\"http://nginx.org/\">Nginx 1.7.8</a> is now available, and I&#8217;m really happy to see this entry in the <a href=\"http://nginx.org/en/CHANGES\">changelog</a>:</p>\n<blockquote><p>\nFeature: now the &#8220;tcp_nodelay&#8221; directive works with SPDY connections.\n</p></blockquote>\n<p>To be more specific, <a href='http://trac.nginx.org/nginx/changeset/2c10db908b8c4a9c0532c58830275d5ad84ae686/nginx/src'>this commit</a>.</p>\n<hr />\n<h3>The Story</h3>\n<p>Back in September I spun up a <a href=\"https://sites.google.com/a/webpagetest.org/docs/private-instances\">private instance</a> of <a href=\"http://webpagetest.org/\">webpagetest</a> ( WPT ).  One of the first things I did was run near optimal condition tests.  I wanted to see what the lower bound were for a few performance tests.  The test system was very close to one of <a href=\"http://automattic.com/\">our</a> data centers ( less than 1ms ping times ), so I configured tests to use Chrome as the browser, with no traffic shaping.</p>\n<p>Like a kid with a new toy on Christmas morning I started running tests against this private WPT instance.  Quickly something odd came up.  In some cases we were seeing requests for very small ( sometimes less than 1kb ) resources take much longer than they should have.  And by &#8220;much longer&#8221;, I mean these were 3 to 4 times slower than requests for larger resources.</p>\n<p>Long story short, these slower small requests were seeing ~200ms delays in time to first byte ( TTFB ).  But it only happened with <a href=\"http://en.wikipedia.org/wiki/SPDY\">SPDY</a>, with compression enabled, for small files ( my tests showed 1,602 bytes or smaller ), when the small file was the first resource requested in the SPDY connection.  Once I was able to list all of the variables that needed to be in place it was very simple to reproduce the problem using WPT.</p>\n<p>Some of you will look at the mention of a ~200ms delay and immediately recognize this as a <a href=\"http://support.microsoft.com/kb/214397\">delayed ack issue</a>:</p>\n<blockquote><p>\nWhen a Microsoft TCP stack receives a data packet, a 200-ms delay timer goes off. When an ACK is eventually sent, the delay timer is reset and will initiate another 200-ms delay when the next data packet is received.\n</p></blockquote>\n<p>( Note that the WPT tester system in our instance uses Windows, so that we can test Internet Explorer )</p>\n<p>But that is why Nginx has a <a href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#tcp_nodelay\">tcp_nodelay</a> option.  Unfortunately it wasn&#8217;t being applied when these variables came together in a SPDY connection.  I started a <a href=\"http://www.webpagetest.org/forums/showthread.php?tid=13322\">thread in the WPT forums</a> about this and we all basically agreed that this was the issue.</p>\n<p>The systems team at <a href=\"http://automattic.com/\">Automattic</a> reached out the Nginx team, describing what we were observing and how to reproduce it.  They sent back a patch, which I ran through my tests and confirmed that it fixed the problem.  The patch led to the <a href=\"http://trac.nginx.org/nginx/changeset/2c10db908b8c4a9c0532c58830275d5ad84ae686/nginx/src\">commit</a> I mentioned above.  And now that change is part of the Nginx 1.7.8 release.</p>\n<h3>Waterfall</h3>\n<p>Here is what this looks like in action.  First, a WPT waterfall graph using Nginx 1.7.7:</p>\n<p><a href=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-177-1.png\"><img loading=\"lazy\" src=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-177-1.png\" alt=\"nginx-177\" width=\"966\" height=\"433\" class=\"aligncenter size-full wp-image-11467\" srcset=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-177-1.png 966w, https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-177-1-300x134.png 300w, https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-177-1-768x344.png 768w\" sizes=\"(max-width: 966px) 100vw, 966px\" /></a></p>\n<p>That TTFB of 212ms is significantly slower than it should be.  Compare that with the same test conditions using Nginx 1.7.8:</p>\n<p><a href=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-178-1.png\"><img loading=\"lazy\" src=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-178-1.png\" alt=\"nginx-178\" width=\"970\" height=\"425\" class=\"aligncenter size-full wp-image-11468\" srcset=\"https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-178-1.png 970w, https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-178-1-300x131.png 300w, https://blog.josephscott.org/wp-content/uploads/2014/12/nginx-178-1-768x336.png 768w\" sizes=\"(max-width: 970px) 100vw, 970px\" /></a></p>\n<p>A TTFB of 15ms is inline with what I expected to see.  Going from 212ms to 15ms is a 14x improvement!  The total request time dropped from 266ms to 69ms, a 3.8X improvement.  I&#8217;ll take gains like that anytime.</p>\n<h3>Reproducing This Yourself</h3>\n<p>I ran numerous tests during this process.  To make running new tests easier I put together a simple script to take care of the Nginx build and configuration:</p>\nView the code on <a href=\"https://gist.github.com/b79e79a8b7e17ca1bdb7\">Gist</a>.\n<p>For each test I&#8217;d spin up a new DigitalOcean VM with Ubuntu 14.04 LTS.  The build script would complete in a few minutes and then I&#8217;d run new WPT tests.</p>\n<p>Conveniently it turns out that the default <a href=\"http://trac.nginx.org/nginx/browser/nginx/docs/html/index.html\">Welcome to nginx!</a> page is small enough to trigger the ~200ms delay.</p>\n<p>With all of that in place you can run a test at <a href=\"http://www.webpagetest.org/\">webpagetest.org</a> to see this in action.  I&#8217;ve been using the following test config:</p>\n<p>&#8211; Test Location: Dulles, VA<br />\n&#8211; Browser: Chrome<br />\n&#8211; Connection: Native Connection ( No Traffic Shaping )<br />\n&#8211; &#8220;Ignore SSL Certificate Errors&#8221; ( under the Advanced tab ) &#8212; this is need because I&#8217;ve been using a self signed cert</p>\n<p>The &#8220;Dulles, VA&#8221; location has a fast enough route to DigitalOcean &#8220;New York 3&#8221; that you can still observe the ~200ms TTFB difference between Nginx 1.7.7 and 1.7.8.</p>\n<hr />\n<p>A big thank you to the Nginx team for fixing this.</p>\n",
            "content_text": "Nginx 1.7.8 is now available, and I&#8217;m really happy to see this entry in the changelog:\n\nFeature: now the &#8220;tcp_nodelay&#8221; directive works with SPDY connections.\n\nTo be more specific, this commit.\n\nThe Story\nBack in September I spun up a private instance of webpagetest ( WPT ).  One of the first things I did was run near optimal condition tests.  I wanted to see what the lower bound were for a few performance tests.  The test system was very close to one of our data centers ( less than 1ms ping times ), so I configured tests to use Chrome as the browser, with no traffic shaping.\nLike a kid with a new toy on Christmas morning I started running tests against this private WPT instance.  Quickly something odd came up.  In some cases we were seeing requests for very small ( sometimes less than 1kb ) resources take much longer than they should have.  And by &#8220;much longer&#8221;, I mean these were 3 to 4 times slower than requests for larger resources.\nLong story short, these slower small requests were seeing ~200ms delays in time to first byte ( TTFB ).  But it only happened with SPDY, with compression enabled, for small files ( my tests showed 1,602 bytes or smaller ), when the small file was the first resource requested in the SPDY connection.  Once I was able to list all of the variables that needed to be in place it was very simple to reproduce the problem using WPT.\nSome of you will look at the mention of a ~200ms delay and immediately recognize this as a delayed ack issue:\n\nWhen a Microsoft TCP stack receives a data packet, a 200-ms delay timer goes off. When an ACK is eventually sent, the delay timer is reset and will initiate another 200-ms delay when the next data packet is received.\n\n( Note that the WPT tester system in our instance uses Windows, so that we can test Internet Explorer )\nBut that is why Nginx has a tcp_nodelay option.  Unfortunately it wasn&#8217;t being applied when these variables came together in a SPDY connection.  I started a thread in the WPT forums about this and we all basically agreed that this was the issue.\nThe systems team at Automattic reached out the Nginx team, describing what we were observing and how to reproduce it.  They sent back a patch, which I ran through my tests and confirmed that it fixed the problem.  The patch led to the commit I mentioned above.  And now that change is part of the Nginx 1.7.8 release.\nWaterfall\nHere is what this looks like in action.  First, a WPT waterfall graph using Nginx 1.7.7:\n\nThat TTFB of 212ms is significantly slower than it should be.  Compare that with the same test conditions using Nginx 1.7.8:\n\nA TTFB of 15ms is inline with what I expected to see.  Going from 212ms to 15ms is a 14x improvement!  The total request time dropped from 266ms to 69ms, a 3.8X improvement.  I&#8217;ll take gains like that anytime.\nReproducing This Yourself\nI ran numerous tests during this process.  To make running new tests easier I put together a simple script to take care of the Nginx build and configuration:\nView the code on Gist.\nFor each test I&#8217;d spin up a new DigitalOcean VM with Ubuntu 14.04 LTS.  The build script would complete in a few minutes and then I&#8217;d run new WPT tests.\nConveniently it turns out that the default Welcome to nginx! page is small enough to trigger the ~200ms delay.\nWith all of that in place you can run a test at webpagetest.org to see this in action.  I&#8217;ve been using the following test config:\n&#8211; Test Location: Dulles, VA\n&#8211; Browser: Chrome\n&#8211; Connection: Native Connection ( No Traffic Shaping )\n&#8211; &#8220;Ignore SSL Certificate Errors&#8221; ( under the Advanced tab ) &#8212; this is need because I&#8217;ve been using a self signed cert\nThe &#8220;Dulles, VA&#8221; location has a fast enough route to DigitalOcean &#8220;New York 3&#8221; that you can still observe the ~200ms TTFB difference between Nginx 1.7.7 and 1.7.8.\n\nA big thank you to the Nginx team for fixing this.",
            "date_published": "2014-12-03T18:03:55-07:00",
            "date_modified": "2014-12-03T18:03:55-07:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "nginx",
                "spdy",
                "webperf",
                "Posts"
            ]
        },
        {
            "id": "https://josephscott.org/?p=11443",
            "url": "https://blog.josephscott.org/2014/12/02/how-to-check-a-site-for-spdy-support-with-openssl/",
            "title": "How To Check A Site For SPDY Support With OpenSSL",
            "content_html": "<p>A <a href=\"http://stackoverflow.com/questions/23742928/how-to-detect-if-a-server-is-using-spdy/23792880#23792880\">Stack Overflow thread</a> with an example on how to check a server for <a href=\"http://www.chromium.org/spdy\">SPDY</a> support with <a href=\"https://www.openssl.org/\">OpenSSL</a>:</p>\n<pre>\nopenssl s_client -connect google.com:443 -nextprotoneg ''\n</pre>\n<p>The result I got from &#8220;OpenSSL 1.0.1f 6 Jan 2014&#8221; looked like this ( emphasis mine ):</p>\n<pre>\nCONNECTED(00000003)\n<strong>Protocols advertised by server: spdy/5a1, h2-14, spdy/3.1, spdy/3, http/1.1</strong>\n139790806673056:error:140920E3:SSL routines:SSL3_GET_SERVER_HELLO:parse tlsext:s3_clnt.c:1061:\n---\nno peer certificate available\n---\nNo client certificate CA names sent\n---\nSSL handshake has read 110 bytes and written 7 bytes\n---\nNew, (NONE), Cipher is (NONE)\nSecure Renegotiation IS supported\nCompression: NONE\nExpansion: NONE\nNext protocol: (2) \nSSL-Session:\n    Protocol  : TLSv1.2\n    Cipher    : 0000\n    Session-ID: \n    Session-ID-ctx: \n    Master-Key: \n    Key-Arg   : None\n    PSK identity: None\n    PSK identity hint: None\n    SRP username: None\n    Start Time: 1417496091\n    Timeout   : 300 (sec)\n    Verify return code: 0 (ok)\n---\n</pre>\n<p>The &#8220;Protocols advertised by server:&#8221; is the line you need.</p>\n",
            "content_text": "A Stack Overflow thread with an example on how to check a server for SPDY support with OpenSSL:\n\nopenssl s_client -connect google.com:443 -nextprotoneg ''\n\nThe result I got from &#8220;OpenSSL 1.0.1f 6 Jan 2014&#8221; looked like this ( emphasis mine ):\n\nCONNECTED(00000003)\nProtocols advertised by server: spdy/5a1, h2-14, spdy/3.1, spdy/3, http/1.1\n139790806673056:error:140920E3:SSL routines:SSL3_GET_SERVER_HELLO:parse tlsext:s3_clnt.c:1061:\n---\nno peer certificate available\n---\nNo client certificate CA names sent\n---\nSSL handshake has read 110 bytes and written 7 bytes\n---\nNew, (NONE), Cipher is (NONE)\nSecure Renegotiation IS supported\nCompression: NONE\nExpansion: NONE\nNext protocol: (2) \nSSL-Session:\n    Protocol  : TLSv1.2\n    Cipher    : 0000\n    Session-ID: \n    Session-ID-ctx: \n    Master-Key: \n    Key-Arg   : None\n    PSK identity: None\n    PSK identity hint: None\n    SRP username: None\n    Start Time: 1417496091\n    Timeout   : 300 (sec)\n    Verify return code: 0 (ok)\n---\n\nThe &#8220;Protocols advertised by server:&#8221; is the line you need.",
            "date_published": "2014-12-02T16:15:21-07:00",
            "date_modified": "2014-12-02T16:15:21-07:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "http",
                "openssl",
                "spdy",
                "Posts"
            ]
        },
        {
            "id": "https://josephscott.org/?p=10358",
            "url": "https://blog.josephscott.org/2014/04/28/tried-spdy/",
            "title": "Tried Out SPDY",
            "content_html": "<p>Zack Tollman suggested I <a href=\"https://josephscott.org/archives/2014/04/update-nginx-for-better-https-performance/#comment-15955\" title=\"Comments like these make writing posts more enjoyable.\">try out SPDY</a> with my updated Nginx install.  While I&#8217;m sad at the idea of giving up a plain text HTTP API, I was curious to see what SPDY looked like on this site.</p>\n<p>I was disappointed with the results.  The fastest page load time out of 5 runs without SPDY was 1.039 s.  With SPDY the fastest result was 1.273 s.  I then did several more runs of the same test with SPDY enabled to see if any of them could get close to the 1.0 s base line.  None of them did, most came in close to 2 seconds.  I had honestly expected to see SPDY perform better.  That said this type of testing is not particularly rigorous, so take these numbers with a sufficiently large grain of salt.</p>\n<p>Given the initial poor showing of SPDY in these tests I&#8217;m going to leave it turned off for now.</p>\n",
            "content_text": "Zack Tollman suggested I try out SPDY with my updated Nginx install.  While I&#8217;m sad at the idea of giving up a plain text HTTP API, I was curious to see what SPDY looked like on this site.\nI was disappointed with the results.  The fastest page load time out of 5 runs without SPDY was 1.039 s.  With SPDY the fastest result was 1.273 s.  I then did several more runs of the same test with SPDY enabled to see if any of them could get close to the 1.0 s base line.  None of them did, most came in close to 2 seconds.  I had honestly expected to see SPDY perform better.  That said this type of testing is not particularly rigorous, so take these numbers with a sufficiently large grain of salt.\nGiven the initial poor showing of SPDY in these tests I&#8217;m going to leave it turned off for now.",
            "date_published": "2014-04-28T13:52:14-06:00",
            "date_modified": "2014-04-28T13:52:14-06:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "http",
                "nginx",
                "performance",
                "spdy",
                "Posts"
            ]
        }
    ]
}