{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://blog.josephscott.org/category/os/linux/feed/json/ -- and add it your reader.",
    "home_page_url": "https://blog.josephscott.org/category/os/linux/",
    "feed_url": "https://blog.josephscott.org/category/os/linux/feed/json/",
    "language": "en-US",
    "title": "Linux &#8211; Joseph Scott",
    "items": [
        {
            "id": "http://joseph.randomnetworks.com/archives/2005/05/13/everybody-caches/",
            "url": "https://blog.josephscott.org/2005/05/13/everybody-caches/",
            "title": "Everybody Caches",
            "content_html": "<p>Caching is one of the techniques used in software and hardware to make things faster.  We usually like things to be fast, so we are usually happy to use systems that cache in a variety of ways.  Let&#8217;s face it, everybody caches.</p>\n<p>If you&#8217;ve been living on this planet for awhile now you&#8217;ll recognize that it is pretty rare that you get something for nothing.  It&#8217;s no different with caching.  The OS on your computer caches reads and writes to your hard drive, and from time to time will flush that cache out to disk.  It&#8217;s important that this flush happens so that when you loose power your data is on the hard drive, not memory.  Except that everybody caches, this includes your hard drives.  So when your OS goes to flush data to the disk, the disk caches it in its own memory and eventually flushes to the actual disk portion of the drive.  Once again this is all down in the name of speed.  And once again the biggest risk of this is loss of data when the power goes out.  You want to note that this is why many RAID controllers will often have a small battery to keep that data they&#8217;ve cached in memory still there for a day or two, by which time we hope the power will have been restored.</p>\n<p>Hopefully none of the above is news, this has been the situation for computers and hard drives for years.  It is news for at least some folks though, other wise the <a href=\"http://slashdot.org/\">Slashdot</a> crowd wouldn&#8217;t be so surprised that <a href=\"http://hardware.slashdot.org/article.pl?sid=05/05/13/0529252&amp;tid=198&amp;tid=128\">your hard drive lies to you</a>.  This discussion seems to have been touched off by a <a href=\"http://www.livejournal.com/~brad/2116715.html\">tool that demos your hard drive caching</a> and how you can turn it off in Linux.  Brad wrote this tool as a result of <a href=\"http://www.livejournal.com/community/lj_dev/670215.html\">LiveJournal&#8217;s outage</a>, where data loss do to drive write caching seems to have been a pretty major problem for them.  Not long after LJs problems <a href=\"http://news.netcraft.com/archives/2005/02/22/power_outage_knocks_wikipedia_offline.html\">Wikipedia was offline for the same reason</a>.</p>\n<p>Some of the comments on the Slashdot article about hard drives caching did provide good information.  One <a href=\"http://hardware.slashdot.org/comments.pl?sid=149349&amp;cid=12517596\">comment pointed out caching issues mentioned on various man pages</a> from Mac OS X, Linux and FreeBSD.  This comment was interesting because it references another point in time where there was a lot of discussion about what do with hard drive caching and the risks there of.  The FreeBSD man page quoted in the comment references FreeBSD 4.3, which was <a href=\"http://www.freebsd.org/releases/\">released four years ago</a>.  I remember the huge discussion that broke out about disabling hard drive caching in FreeBSD.  Many argued that the risks of data of loss were just too great, but in the end the huge performance loss when turning off the hard drive caching was just too much bare.</p>\n<p>Thankfully another comment also pointed to an <a href=\"http://lists.apple.com/archives/darwin-dev/2005/Feb/msg00072.html\">Apple email about hard drive caching</a>.  If you deal with file storage go read that, it is very informative.  The lesson learned is that for plain average systems with off the shelf hard drives, you may or may not be able to convince your hard drive to put data on to the disk manually.</p>\n<p>Just remember, everybody caches, so plan accordingly.</p>\n",
            "content_text": "Caching is one of the techniques used in software and hardware to make things faster.  We usually like things to be fast, so we are usually happy to use systems that cache in a variety of ways.  Let&#8217;s face it, everybody caches.\nIf you&#8217;ve been living on this planet for awhile now you&#8217;ll recognize that it is pretty rare that you get something for nothing.  It&#8217;s no different with caching.  The OS on your computer caches reads and writes to your hard drive, and from time to time will flush that cache out to disk.  It&#8217;s important that this flush happens so that when you loose power your data is on the hard drive, not memory.  Except that everybody caches, this includes your hard drives.  So when your OS goes to flush data to the disk, the disk caches it in its own memory and eventually flushes to the actual disk portion of the drive.  Once again this is all down in the name of speed.  And once again the biggest risk of this is loss of data when the power goes out.  You want to note that this is why many RAID controllers will often have a small battery to keep that data they&#8217;ve cached in memory still there for a day or two, by which time we hope the power will have been restored.\nHopefully none of the above is news, this has been the situation for computers and hard drives for years.  It is news for at least some folks though, other wise the Slashdot crowd wouldn&#8217;t be so surprised that your hard drive lies to you.  This discussion seems to have been touched off by a tool that demos your hard drive caching and how you can turn it off in Linux.  Brad wrote this tool as a result of LiveJournal&#8217;s outage, where data loss do to drive write caching seems to have been a pretty major problem for them.  Not long after LJs problems Wikipedia was offline for the same reason.\nSome of the comments on the Slashdot article about hard drives caching did provide good information.  One comment pointed out caching issues mentioned on various man pages from Mac OS X, Linux and FreeBSD.  This comment was interesting because it references another point in time where there was a lot of discussion about what do with hard drive caching and the risks there of.  The FreeBSD man page quoted in the comment references FreeBSD 4.3, which was released four years ago.  I remember the huge discussion that broke out about disabling hard drive caching in FreeBSD.  Many argued that the risks of data of loss were just too great, but in the end the huge performance loss when turning off the hard drive caching was just too much bare.\nThankfully another comment also pointed to an Apple email about hard drive caching.  If you deal with file storage go read that, it is very informative.  The lesson learned is that for plain average systems with off the shelf hard drives, you may or may not be able to convince your hard drive to put data on to the disk manually.\nJust remember, everybody caches, so plan accordingly.",
            "date_published": "2005-05-13T09:39:08-06:00",
            "date_modified": "2005-05-13T09:39:08-06:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "FreeBSD",
                "Linux",
                "Mac OS X",
                "OS",
                "Windows"
            ]
        },
        {
            "id": "http://joseph.randomnetworks.com/archives/2005/02/11/mysql-performance-on-linux-opennetfreebsd-and-solaris/",
            "url": "https://blog.josephscott.org/2005/02/11/mysql-performance-on-linux-opennetfreebsd-and-solaris/",
            "title": "MySQL Performance On Linux, (Open|Net|Free)BSD and Solaris",
            "content_html": "<p>The world of benchmarks is fraught with peril, those who enter are likely to get flamed, not matter what the results are.  I had already prepared myself for the worst when I saw the title of <a href=\"http://software.newsforge.com/software/04/12/27/1238216.shtml?tid=152&amp;tid=72&amp;tid=29\">Using MySQL to benchmark OS performance</a> on NewsForge the other day.  After reading through it, and part 2, <a href=\"http://software.newsforge.com/article.pl?sid=04/12/27/1243207\">Comparing MySQL performance</a>, I was pleasantly surprised.  At the end of the article I got the feeling that <a href=\"http://vegan.net/tony/\">Tony Bourke</a> had made an honest attempt at testing MySQL 4.0.22 on the following operating systems:</p>\n<ul>\n<li>FreeBSD 4.11</li>\n<li>FreeBSD 5.3</li>\n<li>NetBSD 2.0</li>\n<li>Linux 2.6</li>\n<li>Linux 2.4</li>\n<li>Solaris 10 x86 (build 69)</li>\n<li>OpenBSD 3.6</li>\n</ul>\n<p>While there are things that I&#8217;d recommend doing differently, it certainly seems like Tony did a good job to trying to make this as balanced as possible.  Perhaps my biggest beef with his methods was the decision to run all of the tests locally, instead over the network.  To his credit he does a good job explaining why he ended up not doing so, but that doesn&#8217;t change the fact that for those building apps (web or otherwise), don&#8217;t usually run that application on the same system that is running MySQL.</p>\n<p>The results of the test still feel a little bit odd.  I can&#8217;t really hold this against Tony though, I&#8217;m sure he was working on a deadline and if you put off publishing forever then why bother doing it in the first place.  That said, I suspect that there is more that could be done if more time and resources were available.  Some of the other obvious possibilities include using MySQL built for that OS (rpm&#8217;s, BSD ports, etc), looking at additional file system tweaks and differences (does Linux still default to async fs mounts?) and trying different versions of MySQL (4.1 just went into production, but 5.x betas have been around for awhile too).</p>\n",
            "content_text": "The world of benchmarks is fraught with peril, those who enter are likely to get flamed, not matter what the results are.  I had already prepared myself for the worst when I saw the title of Using MySQL to benchmark OS performance on NewsForge the other day.  After reading through it, and part 2, Comparing MySQL performance, I was pleasantly surprised.  At the end of the article I got the feeling that Tony Bourke had made an honest attempt at testing MySQL 4.0.22 on the following operating systems:\n\nFreeBSD 4.11\nFreeBSD 5.3\nNetBSD 2.0\nLinux 2.6\nLinux 2.4\nSolaris 10 x86 (build 69)\nOpenBSD 3.6\n\nWhile there are things that I&#8217;d recommend doing differently, it certainly seems like Tony did a good job to trying to make this as balanced as possible.  Perhaps my biggest beef with his methods was the decision to run all of the tests locally, instead over the network.  To his credit he does a good job explaining why he ended up not doing so, but that doesn&#8217;t change the fact that for those building apps (web or otherwise), don&#8217;t usually run that application on the same system that is running MySQL.\nThe results of the test still feel a little bit odd.  I can&#8217;t really hold this against Tony though, I&#8217;m sure he was working on a deadline and if you put off publishing forever then why bother doing it in the first place.  That said, I suspect that there is more that could be done if more time and resources were available.  Some of the other obvious possibilities include using MySQL built for that OS (rpm&#8217;s, BSD ports, etc), looking at additional file system tweaks and differences (does Linux still default to async fs mounts?) and trying different versions of MySQL (4.1 just went into production, but 5.x betas have been around for awhile too).",
            "date_published": "2005-02-11T14:37:26-07:00",
            "date_modified": "2005-02-11T14:37:26-07:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "Database",
                "FreeBSD",
                "Linux",
                "MySQL",
                "OS"
            ]
        },
        {
            "id": "http://joseph.randomnetworks.com/archives/2005/01/06/honeynet-linux-security-trends/",
            "url": "https://blog.josephscott.org/2005/01/06/honeynet-linux-security-trends/",
            "title": "Honeynet: Linux Security Trends",
            "content_html": "<p>Recently I&#8217;ve started reading <a href=\"http://www.schneier.com/blog/\">Bruce Schneier&#8217;s Blog</a> regularly.  I especially enjoy it when it he exposes what should be obvious holes in the logic of strange security measures.  That&#8217;s why I was so disappointed to see him praise <a href=\"http://www.honeynet.org/\">The Honeynet Project</a>&#8216;s paper on the <a href=\"http://www.honeynet.org/papers/trends/life-linux.pdf\">life expectancy of unpatched or vulnerable Linux systems</a>.  I was going to simply leave a comment on the entry, but after reading the pdf there are so many issues that I figured I&#8217;d post this myself.  So here are some of things that I take issue with in this report and why I&#8217;m disappointed that someone like Bruce (who is on their board of directors) would <a href=\"http://www.schneier.com/blog/archives/2005/01/linux_security.html\">praise it</a>.</p>\n<p>First off, Bruce&#8217;s main focus, that &#8220;Linux&#8221; (in reality they mean, mostly Red Hat Linux, not Linux) will sit on the net for an average of 3 months before being compromised.  While this is interesting, it is pretty much useless for security purposes.  Since this is an average, obviously some systems were compromised sooner and some later.  When it comes to security, who cares what the average is, you secure your systems.  I mean, really, can you imagine a security expert simply shrugging off securing a Red Hat system simply because on average it won&#8217;t be compromised by a random attacker for three months?</p>\n<p>Even though the intention of this pdf seems to be to show how much more likely a Win32 system is to be randomly compromised than a Linux (again, mostly Red Hat), they do mention that they had deployed vulnerable Win32 systems that went &#8220;several months&#8221; before compromised (2 in Brazil).  I&#8217;m not trying to defend Window system security, but we&#8217;ve seen Microsoft (and others) play with numbers to make things come out in their favor, I&#8217;d hate to see people like Bruce doing the same.</p>\n<p>In additional to the Linux (you guessed it, mostly Red Hat) systems they also deployed one FreeBSD 4.4 system, two Sparc Solaris 8 and two Sparc Solaris 9 systems.  Of these they mention that three were compromised within three weeks and the fourth went for six months.  If we assume that average for the Solaris systems was one week, this gives an average for more than ten months.  The article is quick to point out that &#8220;There is not enough data here to attempt any conclusions&#8221;.  If four Solaris systems aren&#8217;t enough to provide meaningful conclusions, then why bother deploying them in the first place?  If they were interested comparing different Unix like systems then they should deploy enough to actually compare them.  And what of the FreeBSD 4.4 system?  There is no further mention of it, we are given no details on how long it lasted.  For completeness I should mention that they also deployed two Suse Linux and two Fedora Core 1 Linux systems.</p>\n<p>The whole feeling of this article is how we can try to provide more number to try and bash Microsoft.  What&#8217;s the point in that?  Want to do something useful, deploy several different systems: Windows 2000, Windows 2003, Red Hat Linux, Suse Linux, Fedora, Mandrake, Debian, FreeBSD, NetBSD and OpenBSD.  Make sure that there are enough of each to come to some conclusion, otherwise why bother?</p>\n<p>I hope Bruce continues to hammer people making silly security statements, I just hope that he doesn&#8217;t exclude his keen eye when it comes to projects that he is a part of.</p>\n<p><strong>UPDATE: 7:05pm 17 Jan 2005</strong>: Why does <a href=\"http://it.slashdot.org/article.pl?sid=05/01/18/0218242\">Slashdot even bother</a> to link to these types of things?</p>\n",
            "content_text": "Recently I&#8217;ve started reading Bruce Schneier&#8217;s Blog regularly.  I especially enjoy it when it he exposes what should be obvious holes in the logic of strange security measures.  That&#8217;s why I was so disappointed to see him praise The Honeynet Project&#8216;s paper on the life expectancy of unpatched or vulnerable Linux systems.  I was going to simply leave a comment on the entry, but after reading the pdf there are so many issues that I figured I&#8217;d post this myself.  So here are some of things that I take issue with in this report and why I&#8217;m disappointed that someone like Bruce (who is on their board of directors) would praise it.\nFirst off, Bruce&#8217;s main focus, that &#8220;Linux&#8221; (in reality they mean, mostly Red Hat Linux, not Linux) will sit on the net for an average of 3 months before being compromised.  While this is interesting, it is pretty much useless for security purposes.  Since this is an average, obviously some systems were compromised sooner and some later.  When it comes to security, who cares what the average is, you secure your systems.  I mean, really, can you imagine a security expert simply shrugging off securing a Red Hat system simply because on average it won&#8217;t be compromised by a random attacker for three months?\nEven though the intention of this pdf seems to be to show how much more likely a Win32 system is to be randomly compromised than a Linux (again, mostly Red Hat), they do mention that they had deployed vulnerable Win32 systems that went &#8220;several months&#8221; before compromised (2 in Brazil).  I&#8217;m not trying to defend Window system security, but we&#8217;ve seen Microsoft (and others) play with numbers to make things come out in their favor, I&#8217;d hate to see people like Bruce doing the same.\nIn additional to the Linux (you guessed it, mostly Red Hat) systems they also deployed one FreeBSD 4.4 system, two Sparc Solaris 8 and two Sparc Solaris 9 systems.  Of these they mention that three were compromised within three weeks and the fourth went for six months.  If we assume that average for the Solaris systems was one week, this gives an average for more than ten months.  The article is quick to point out that &#8220;There is not enough data here to attempt any conclusions&#8221;.  If four Solaris systems aren&#8217;t enough to provide meaningful conclusions, then why bother deploying them in the first place?  If they were interested comparing different Unix like systems then they should deploy enough to actually compare them.  And what of the FreeBSD 4.4 system?  There is no further mention of it, we are given no details on how long it lasted.  For completeness I should mention that they also deployed two Suse Linux and two Fedora Core 1 Linux systems.\nThe whole feeling of this article is how we can try to provide more number to try and bash Microsoft.  What&#8217;s the point in that?  Want to do something useful, deploy several different systems: Windows 2000, Windows 2003, Red Hat Linux, Suse Linux, Fedora, Mandrake, Debian, FreeBSD, NetBSD and OpenBSD.  Make sure that there are enough of each to come to some conclusion, otherwise why bother?\nI hope Bruce continues to hammer people making silly security statements, I just hope that he doesn&#8217;t exclude his keen eye when it comes to projects that he is a part of.\nUPDATE: 7:05pm 17 Jan 2005: Why does Slashdot even bother to link to these types of things?",
            "date_published": "2005-01-06T16:57:11-07:00",
            "date_modified": "2005-01-06T16:57:11-07:00",
            "authors": [
                {
                    "name": "josephscott",
                    "url": "https://blog.josephscott.org/author/josephscott/",
                    "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
                }
            ],
            "author": {
                "name": "josephscott",
                "url": "https://blog.josephscott.org/author/josephscott/",
                "avatar": "https://secure.gravatar.com/avatar/582b66ad5ae1b69c7601a990cb9a661a?s=512&d=mm&r=g"
            },
            "tags": [
                "Linux",
                "OS"
            ]
        }
    ]
}